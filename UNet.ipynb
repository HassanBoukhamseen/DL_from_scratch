{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "UNet.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "0I5v0AVAArgj"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "import torchvision\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor, Compose, Normalize, RandomRotation, Resize\n",
        "from torch.utils.data import DataLoader\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import math"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mx3VebGABI2p"
      },
      "source": [
        "class DoubleConv(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size=3):\n",
        "        super(DoubleConv, self).__init__()\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, kernel_size), \n",
        "            nn.ReLU(inplace=True), \n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.Conv2d(out_channels, out_channels, kernel_size), \n",
        "            nn.ReLU(inplace=True), \n",
        "            nn.BatchNorm2d(out_channels),\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        return self.conv(x)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jmbEA2OrU220"
      },
      "source": [
        "def crop_and_concat(tens1, tens2):\n",
        "    tens1_size = tens1.size()[2]\n",
        "    tens2_size = tens2.size()[2]\n",
        "    diff = (tens1_size - tens2_size) // 2\n",
        "    tens1 = tens1[:, :, diff:tens1_size-diff, diff:tens1_size-diff]\n",
        "    return torch.cat([tens1, tens2], dim=1)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NtkXqVWWBd1n"
      },
      "source": [
        "class UNet(nn.Module):\n",
        "    def __init__(self, in_channels=3, out_channels=1):\n",
        "        super(UNet, self).__init__()\n",
        "        self.max_pool = nn.MaxPool2d(2, 2)\n",
        "        # encoder\n",
        "        self.down_1 = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, kernel_size=3, padding=174), \n",
        "            nn.ReLU(inplace=True), \n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.Conv2d(64, 64, kernel_size=3), \n",
        "            nn.ReLU(inplace=True), \n",
        "            nn.BatchNorm2d(64),\n",
        "        )\n",
        "        self.down_2 = DoubleConv(64, 128)\n",
        "        self.down_3 = DoubleConv(128, 256)\n",
        "        self.down_4 = DoubleConv(256, 512)\n",
        "        # bottle_neck\n",
        "        self.conv_1 = nn.Conv2d(512, 1024, 3)\n",
        "        self.conv_2 = nn.Conv2d(1024, 1024, 3)\n",
        "        # decoder\n",
        "        self.up_conv_1 = nn.ConvTranspose2d(1024, 512, kernel_size=2, stride=2)\n",
        "        self.up_1 = DoubleConv(1024, 512)\n",
        "        self.up_conv_2 = nn.ConvTranspose2d(512, 256, kernel_size=2, stride=2)\n",
        "        self.up_2 = DoubleConv(512, 256)\n",
        "        self.up_conv_3 = nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2)\n",
        "        self.up_3 = DoubleConv(256, 128)\n",
        "        self.up_conv_4 = nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2)\n",
        "        self.up_4 = DoubleConv(128, 64)\n",
        "        \n",
        "        #output\n",
        "        self.one_by_one_conv = nn.Conv2d(64,1, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        #decoder\n",
        "        x1 = self.down_1(x)\n",
        "        x2 = self.max_pool(x1)\n",
        "\n",
        "        x3 = self.down_2(x2)\n",
        "        x4 = self.max_pool(x3)\n",
        "\n",
        "        x5 = self.down_3(x4)\n",
        "        x6 = self.max_pool(x5)\n",
        "\n",
        "        x7 = self.down_4(x6)\n",
        "        x8 = self.max_pool(x7)\n",
        "\n",
        "        #bottle_neck\n",
        "        x9 = self.conv_1(x8)\n",
        "        x10 = self.conv_2(x9)\n",
        "\n",
        "        #encoder\n",
        "        x11 = self.up_conv_1(x10)\n",
        "        x12 = crop_and_concat(x7, x11)\n",
        "        x13 = self.up_1(x12)\n",
        "\n",
        "        x14 = self.up_conv_2(x13)\n",
        "        x15 = crop_and_concat(x5, x14)\n",
        "        x16 = self.up_2(x15)\n",
        "\n",
        "        x17 = self.up_conv_3(x16)\n",
        "        x18 = crop_and_concat(x3, x17)\n",
        "        x19 = self.up_3(x18)\n",
        "\n",
        "        x20 = self.up_conv_4(x19)\n",
        "        x21 = crop_and_concat(x1, x20)\n",
        "        x22 = self.up_4(x21)\n",
        "        \n",
        "        #output\n",
        "        x22 = self.one_by_one_conv(x22)\n",
        "        return x22"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "arAGiH0FCFrI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b0cf7fbe-4b34-4464-c70d-28bf08905cb4"
      },
      "source": [
        "\n",
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = UNet().to(DEVICE)\n",
        "x = torch.randn((1, 3, 224, 224)).to(DEVICE)\n",
        "output = model(x)\n",
        "print(output.shape)\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 1, 388, 388])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
            "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
          ]
        }
      ]
    }
  ]
}